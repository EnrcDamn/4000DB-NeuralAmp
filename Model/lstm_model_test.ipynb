{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO USE: \n",
    "#    1. Upload your input and output wav files to the current directory in Colab\n",
    "#    2. Edit the USER INPUTS section to point to your wav files, and choose a\n",
    "#         model name, and number of epochs for training. \n",
    "#    3. Run each section of code. The trained models and output wav files will be \n",
    "#         added to the \"models\" directory.\n",
    "#\n",
    "#     Note: Tested on CPU and GPU runtimes.\n",
    "#     Note: Uses MSE for loss calculation instead of Error to Signal with Pre-emphasis filter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.activations import tanh, elu, relu\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS SECTION FOR USER INPUTS\n",
    "#\n",
    "name = 'test'\n",
    "in_file = 'Data/input_FP32.wav'\n",
    "out_file = 'Data/input_FP32.wav'\n",
    "epochs = 60\n",
    "\n",
    "train_mode = 2     # 0 = speed training, \n",
    "                   # 1 = accuracy training \n",
    "                   # 2 = extended training\n",
    "\n",
    "input_size = 150 \n",
    "\n",
    "if not os.path.exists('models/'+name):\n",
    "    os.makedirs('models/'+name)\n",
    "else:\n",
    "    print(\"A model with the same name already exists. Please choose a new name.\")\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8246700,) (8246700,)\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "in_rate, in_data = wavfile.read(in_file)\n",
    "out_rate, out_data = wavfile.read(out_file)\n",
    "print(in_data.shape, out_data.shape)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowArray(Sequence):\n",
    "        \n",
    "    def __init__(self, x, y, window_len, batch_size=32):\n",
    "        self.x = x\n",
    "        self.y = y[window_len-1:] \n",
    "        self.window_len = window_len\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.x) - self.window_len +1) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x_out = np.stack([self.x[idx: idx+self.window_len] for idx in range(index*self.batch_size, (index+1)*self.batch_size)])\n",
    "        y_out = self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 50, 36)            468       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 17, 36)            15588     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 96)                51072     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,225\n",
      "Trainable params: 67,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "1610/1610 [==============================] - 57s 21ms/step - loss: 8.1494e-05 - error_to_signal: 1.1051 - val_loss: 7.4074e-07 - val_error_to_signal: 1069.2587\n",
      "Epoch 2/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 1.6147e-06 - error_to_signal: 0.3274 - val_loss: 2.3171e-07 - val_error_to_signal: 13243.2148\n",
      "Epoch 3/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 6.4901e-06 - error_to_signal: 0.9402 - val_loss: 1.1454e-06 - val_error_to_signal: 9476.5908\n",
      "Epoch 4/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 6.0358e-06 - error_to_signal: 0.0405 - val_loss: 5.6948e-08 - val_error_to_signal: 984.6420\n",
      "Epoch 5/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 3.0610e-06 - error_to_signal: 0.0346 - val_loss: 1.0528e-07 - val_error_to_signal: 9152.9336\n",
      "Epoch 6/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 1.0890e-06 - error_to_signal: 0.1556 - val_loss: 2.3437e-06 - val_error_to_signal: 30122.6367\n",
      "Epoch 7/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 4.3904e-06 - error_to_signal: 0.0663 - val_loss: 3.4710e-07 - val_error_to_signal: 3611.7510\n",
      "Epoch 8/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 2.8864e-06 - error_to_signal: 0.0505 - val_loss: 4.7412e-07 - val_error_to_signal: 117.6954\n",
      "Epoch 9/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 1.5348e-06 - error_to_signal: 0.0684 - val_loss: 2.7383e-08 - val_error_to_signal: 1149.3378\n",
      "Epoch 10/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 4.2469e-06 - error_to_signal: 0.2375 - val_loss: 2.2167e-06 - val_error_to_signal: 14791.7334\n",
      "Epoch 11/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 1.5671e-06 - error_to_signal: 0.0152 - val_loss: 3.0909e-07 - val_error_to_signal: 5488.5815\n",
      "Epoch 12/60\n",
      "1610/1610 [==============================] - 34s 21ms/step - loss: 1.5499e-06 - error_to_signal: 0.0371 - val_loss: 3.7306e-08 - val_error_to_signal: 864.3528\n",
      "Epoch 13/60\n",
      "1610/1610 [==============================] - 33s 21ms/step - loss: 7.9615e-07 - error_to_signal: 0.0417 - val_loss: 1.3941e-07 - val_error_to_signal: 77067.6094\n",
      "Epoch 14/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.9273e-06 - error_to_signal: 0.0963 - val_loss: 1.4284e-07 - val_error_to_signal: 4283.5933\n",
      "Epoch 15/60\n",
      "1610/1610 [==============================] - 33s 20ms/step - loss: 8.5477e-07 - error_to_signal: 0.0181 - val_loss: 2.3286e-08 - val_error_to_signal: 63.8521\n",
      "Epoch 16/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.0896e-06 - error_to_signal: 0.2727 - val_loss: 1.8846e-08 - val_error_to_signal: 5250.1997\n",
      "Epoch 17/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.6546e-06 - error_to_signal: 0.0523 - val_loss: 1.8419e-08 - val_error_to_signal: 111.5145\n",
      "Epoch 18/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.3400e-06 - error_to_signal: 0.0884 - val_loss: 1.9208e-08 - val_error_to_signal: 1099.8319\n",
      "Epoch 19/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.1608e-06 - error_to_signal: 0.2664 - val_loss: 2.3212e-08 - val_error_to_signal: 11635.4619\n",
      "Epoch 20/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 1.4821e-06 - error_to_signal: 0.0140 - val_loss: 9.5958e-07 - val_error_to_signal: 506605.6250\n",
      "Epoch 21/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 1.0916e-06 - error_to_signal: 0.0435 - val_loss: 7.2698e-09 - val_error_to_signal: 16.5489\n",
      "Epoch 22/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.1133e-06 - error_to_signal: 0.0199 - val_loss: 5.5740e-07 - val_error_to_signal: 1069.9640\n",
      "Epoch 23/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 2.8845e-07 - error_to_signal: 0.0356 - val_loss: 3.0652e-08 - val_error_to_signal: 1476.6302\n",
      "Epoch 24/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 1.5729e-06 - error_to_signal: 0.0671 - val_loss: 6.3373e-09 - val_error_to_signal: 206.4691\n",
      "Epoch 25/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 2.2150e-06 - error_to_signal: 0.0668 - val_loss: 8.3589e-09 - val_error_to_signal: 2421.5735\n",
      "Epoch 26/60\n",
      "1610/1610 [==============================] - 31s 20ms/step - loss: 1.5858e-06 - error_to_signal: 0.0587 - val_loss: 5.3224e-09 - val_error_to_signal: 79.1123\n",
      "Epoch 27/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.5592e-06 - error_to_signal: 0.0260 - val_loss: 7.5414e-09 - val_error_to_signal: 2254.1709\n",
      "Epoch 28/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 5.5002e-07 - error_to_signal: 0.0899 - val_loss: 3.9860e-09 - val_error_to_signal: 71.7780\n",
      "Epoch 29/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 7.6261e-07 - error_to_signal: 0.0173 - val_loss: 3.9280e-09 - val_error_to_signal: 116.7820\n",
      "Epoch 30/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 6.0713e-07 - error_to_signal: 0.0207 - val_loss: 5.9866e-09 - val_error_to_signal: 670.2062\n",
      "Epoch 31/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 6.0477e-07 - error_to_signal: 0.0167 - val_loss: 4.7968e-09 - val_error_to_signal: 177.8237\n",
      "Epoch 32/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 6.4579e-07 - error_to_signal: 0.3047 - val_loss: 3.0953e-09 - val_error_to_signal: 69.3640\n",
      "Epoch 33/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.0389e-06 - error_to_signal: 0.0219 - val_loss: 4.4949e-09 - val_error_to_signal: 531.0632\n",
      "Epoch 34/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.2623e-07 - error_to_signal: 0.0273 - val_loss: 1.3835e-07 - val_error_to_signal: 11020.9854\n",
      "Epoch 35/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 9.1258e-07 - error_to_signal: 0.0435 - val_loss: 2.6291e-08 - val_error_to_signal: 3946.3650\n",
      "Epoch 36/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.5357e-07 - error_to_signal: 0.2456 - val_loss: 2.8910e-09 - val_error_to_signal: 98.5268\n",
      "Epoch 37/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.3739e-06 - error_to_signal: 0.0388 - val_loss: 5.1762e-09 - val_error_to_signal: 59.1814\n",
      "Epoch 38/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 8.6921e-08 - error_to_signal: 0.0072 - val_loss: 1.4592e-07 - val_error_to_signal: 361.9627\n",
      "Epoch 39/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.1695e-06 - error_to_signal: 0.0056 - val_loss: 2.6417e-09 - val_error_to_signal: 184.0869\n",
      "Epoch 40/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 6.6639e-07 - error_to_signal: 0.0155 - val_loss: 5.4712e-09 - val_error_to_signal: 668.7251\n",
      "Epoch 41/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.7934e-08 - error_to_signal: 0.0358 - val_loss: 1.0597e-08 - val_error_to_signal: 16.3485\n",
      "Epoch 42/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 5.7745e-07 - error_to_signal: 0.0053 - val_loss: 2.8186e-09 - val_error_to_signal: 9.2763\n",
      "Epoch 43/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 7.8545e-07 - error_to_signal: 0.0832 - val_loss: 3.0866e-09 - val_error_to_signal: 227.9848\n",
      "Epoch 44/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.4508e-07 - error_to_signal: 0.0438 - val_loss: 1.1824e-08 - val_error_to_signal: 1463.4004\n",
      "Epoch 45/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 4.6100e-07 - error_to_signal: 0.0264 - val_loss: 3.3789e-08 - val_error_to_signal: 812.3801\n",
      "Epoch 46/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.1481e-07 - error_to_signal: 0.0270 - val_loss: 4.3349e-07 - val_error_to_signal: 237261.3750\n",
      "Epoch 47/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.4365e-06 - error_to_signal: 0.0451 - val_loss: 5.9305e-09 - val_error_to_signal: 2267.5522\n",
      "Epoch 48/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.2995e-07 - error_to_signal: 0.0117 - val_loss: 6.7052e-07 - val_error_to_signal: 129561.6719\n",
      "Epoch 49/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 4.5643e-07 - error_to_signal: 0.0143 - val_loss: 2.4550e-09 - val_error_to_signal: 47.2118\n",
      "Epoch 50/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.4035e-07 - error_to_signal: 0.0082 - val_loss: 2.3191e-08 - val_error_to_signal: 1070.4518\n",
      "Epoch 51/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.6697e-06 - error_to_signal: 0.0494 - val_loss: 1.5191e-08 - val_error_to_signal: 8025.7432\n",
      "Epoch 52/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 2.4309e-07 - error_to_signal: 0.0249 - val_loss: 3.1650e-09 - val_error_to_signal: 0.1153\n",
      "Epoch 53/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 5.6164e-07 - error_to_signal: 0.0200 - val_loss: 4.8633e-07 - val_error_to_signal: 16809.7012\n",
      "Epoch 54/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.1946e-07 - error_to_signal: 0.0060 - val_loss: 2.2901e-08 - val_error_to_signal: 10715.1963\n",
      "Epoch 55/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.2542e-07 - error_to_signal: 0.0527 - val_loss: 5.1332e-09 - val_error_to_signal: 31.4729\n",
      "Epoch 56/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.0723e-06 - error_to_signal: 0.0450 - val_loss: 1.9086e-08 - val_error_to_signal: 1896.5807\n",
      "Epoch 57/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.7588e-07 - error_to_signal: 0.0058 - val_loss: 1.7529e-09 - val_error_to_signal: 138.6206\n",
      "Epoch 58/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 4.5633e-07 - error_to_signal: 0.0072 - val_loss: 2.6658e-08 - val_error_to_signal: 680.0508\n",
      "Epoch 59/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 3.5814e-07 - error_to_signal: 0.0021 - val_loss: 5.0896e-09 - val_error_to_signal: 2315.7439\n",
      "Epoch 60/60\n",
      "1610/1610 [==============================] - 32s 20ms/step - loss: 1.0694e-06 - error_to_signal: 0.0188 - val_loss: 2.2915e-08 - val_error_to_signal: 10600.7285\n",
      "Running prediction..\n"
     ]
    }
   ],
   "source": [
    "def pre_emphasis_filter(x, coeff=0.95):\n",
    "    return tf.concat([x, x - coeff * x], 1)\n",
    "    \n",
    "def error_to_signal(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Error to signal ratio with pre-emphasis filter:\n",
    "    \"\"\"\n",
    "    y_true, y_pred = pre_emphasis_filter(y_true), pre_emphasis_filter(y_pred)\n",
    "    return K.sum(tf.pow(y_true - y_pred, 2), axis=0) / (K.sum(tf.pow(y_true, 2), axis=0) + 1e-10)\n",
    "    \n",
    "def save_wav(name, data):\n",
    "    wavfile.write(name, 44100, data.flatten().astype(np.float32))\n",
    "\n",
    "def normalize(data):\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_norm = max(data_max,abs(data_min))\n",
    "    return data / data_norm\n",
    "\n",
    "\n",
    "'''This is a similar Tensorflow/Keras implementation of the LSTM model from the paper:\n",
    "    \"Real-Time Guitar Amplifier Emulation with Deep Learning\"\n",
    "    https://www.mdpi.com/2076-3417/10/3/766/htm\n",
    "\n",
    "    Uses a stack of two 1-D Convolutional layers, followed by LSTM, followed by \n",
    "    a Dense (fully connected) layer. Three preset training modes are available, \n",
    "    with further customization by editing the code. A Sequential tf.keras model \n",
    "    is implemented here.\n",
    "\n",
    "    Note: RAM may be a limiting factor for the parameter \"input_size\". The wav data\n",
    "      is preprocessed and stored in RAM, which improves training speed but quickly runs out\n",
    "      if using a large number for \"input_size\".  Reduce this if you are experiencing\n",
    "      RAM issues. \n",
    "    \n",
    "    --training_mode=0   Speed training (default)\n",
    "    --training_mode=1   Accuracy training\n",
    "    --training_mode=2   Extended training (set max_epochs as desired, for example 50+)\n",
    "'''\n",
    "\n",
    "batch_size = 4096 \n",
    "test_size = 0.2\n",
    "\n",
    "if train_mode == 0:         # Speed Training\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 12    \n",
    "    conv1d_filters = 16\n",
    "    hidden_units = 36\n",
    "elif train_mode == 1:       # Accuracy Training (~10x longer than Speed Training)\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 4\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 64\n",
    "else:                       # Extended Training (~60x longer than Accuracy Training)\n",
    "    learning_rate = 0.0005 \n",
    "    conv1d_strides = 3\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 96\n",
    "\n",
    "\n",
    "# Create Sequential Model ###########################################\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None, padding='same',input_shape=(input_size,1)))\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None, padding='same'))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation=None))\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[error_to_signal])\n",
    "model.summary()\n",
    "\n",
    "# Load and Preprocess Data ###########################################\n",
    "in_rate, in_data = wavfile.read(in_file)\n",
    "out_rate, out_data = wavfile.read(out_file)\n",
    "\n",
    "X_all = in_data.astype(np.float32).flatten()  \n",
    "X_all = normalize(X_all).reshape(len(X_all),1)   \n",
    "y_all = out_data.astype(np.float32).flatten() \n",
    "y_all = normalize(y_all).reshape(len(y_all),1)\n",
    "\n",
    "train_examples = int(len(X_all)*0.8)\n",
    "train_arr = WindowArray(X_all[:train_examples], y_all[:train_examples], input_size, batch_size=batch_size)\n",
    "val_arr = WindowArray(X_all[train_examples:], y_all[train_examples:], input_size, batch_size=batch_size)\n",
    "\n",
    "# Train Model ###################################################\n",
    "history = model.fit(train_arr, validation_data=val_arr, epochs=epochs, shuffle=True)    \n",
    "model.save('models/'+name+'/'+name+'.h5')\n",
    "\n",
    "# Run Prediction #################################################\n",
    "print(\"Running prediction..\")\n",
    "\n",
    "# Get the last 20% of the wav data to run prediction and plot results\n",
    "y_the_rest, y_last_part = np.split(y_all, [int(len(y_all)*.8)])\n",
    "x_the_rest, x_last_part = np.split(X_all, [int(len(X_all)*.8)])\n",
    "y_test = y_last_part[input_size-1:] \n",
    "test_arr = WindowArray(x_last_part, y_last_part, input_size, batch_size = batch_size)\n",
    "\n",
    "prediction = model.predict(test_arr)\n",
    "\n",
    "save_wav('models/'+name+'/y_pred.wav', prediction)\n",
    "save_wav('models/'+name+'/x_test.wav', x_last_part)\n",
    "save_wav('models/'+name+'/y_test.wav', y_test)\n",
    "\n",
    "# Add additional data to the saved model (like input_size)\n",
    "filename = 'models/'+name+'/'+name+'.h5'\n",
    "f = h5py.File(filename, 'a')\n",
    "grp = f.create_group(\"info\")\n",
    "dset = grp.create_dataset(\"input_size\", (1,), dtype='int16')\n",
    "dset[0] = input_size\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9338f67d315c6866a694c5b19a58126cb05e126a27e7601fb865c900512a15c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
